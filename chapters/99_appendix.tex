\chapter{Appendix}

% appendix
%\backmatter
\begin{appendices}
%\appendix
%\addcontentsline{toc}{section}{Appendix~\ref{noconvergence}: Proof of Theorem \ref{noconvergence}}
\chapter{Proof of Theorem \ref{noconvergence}}
\label{proof}

For selfish best response approach, the utility function is set as follows,
	\begin{equation}
\label{selfishutility}
		u_i=\frac{\sum_{c(i)=c(i)} f_{ji}+N_0}{P_i\cdot h_i\cdot z_i}
	\end{equation}

\begin{proof}

In order to simplify the proof, we assume $N_0=0$.
Consider one WBS $i$ executing algorithm \ref{whitecatalgo} with utility \ref{selfishutility}, and updates its channel from $c_i$ to $c_i'$, we denote $u_k', k\in \mathcal{N}$ as the utility of WBS $k$ when $i$ chooses channel $c_i'$, accordingly, the summation of utilities of all WBSs after $i$ changing to $c_i'$ is $U'=\sum_{\forall k\in \mathcal{N}, c(i)=c_i'}u_k'$.
\begin{equation}
\label{xxx}
\begin{split}	
U'
& =u_i' + \sum\limits_{j\in\mathcal{N},j\neq i}u_j'\\
& =u_i' + \sum\limits_{j\in\mathcal{N},j\neq i}(u_j+(u_j'-u_j))\\
& =u_i' + \sum\limits_{j\in\mathcal{N},j\neq i}u_j+\sum\limits_{j\in\mathcal{N},j\neq i}(u_j'-u_j)\\
& =u_i' + \sum\limits_{\tiny\substack{j\in\mathcal{N},j\neq i}}u_j + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(u_j'-u_j) + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(u_j'-u_j)\\
&  + \sum\limits_{\tiny\substack{j\in\mathcal{N},j\neq i, \\c(j)\neq c_i', c(j)\neq c_i}}(u_j'-u_j)\\
& =u_i' + \sum\limits_{\tiny\substack{j\in\mathcal{N},j\neq i}}u_j + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{ f_{ij}}{\tilde P_j}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{ f_{ij}}{\tilde P_j})\\
\end{split}
\end{equation}

where,
\begin{equation}
\label{xxxx}
\begin{split}	
u_i'
& = u_i + \varDelta u_i(c_i\rightarrow c_i')\\
& = u_i + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{ f_{ji}}{\tilde P_i}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{ f_{ji}}{\tilde P_i})
\end{split}
\end{equation}

bring \ref{xxxx} into \ref{xxx}, we get,
\begin{equation}
\label{xxxxx}
\begin{split}	
U'
& =U + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{ f_{ji}}{\tilde P_i}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{f_{ji}}{\tilde P_i}) \\
& + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{ f_{ij}}{\tilde P_j}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{f_{ij}}{\tilde P_j})\\
%& =U + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{P_j\cdot h_{ji}+\delta}{P_i'}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{P_j\cdot h_{ji}+\delta}{P_i'}) \\
%& + \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i'}}(\dfrac{P_i\cdot h_{ji}+\delta}{P_j'}) - \sum\limits_{\tiny\substack{j\in\mathcal{N},\\j\neq i, \\c(j)=c_i}}(\dfrac{P_i\cdot h_{ji}+\delta}{P_j'})\\
\end{split}
\end{equation}
According to algorithm \ref{whitecatalgo}, the summation of second and third items, which is the variance of $i$' utility, is negative. If we can confirm the summation of fourth of the last four items is negative, the whole utility of the network decreases with $i$' each update. For simplification, we assume that the channel is symmetric, which means, $h_{ij}=h_{ji}$, and $z$ is identical among all WBSs. Then, the problem we want to confirm is equivalent to the following: Given the in-equation with $n$, $m$ are natural numbers
\begin{equation}
\label{xxxxxx}
\begin{split}	
\sum\limits_{i=1}^{m} \alpha_i < \sum\limits_{i=1}^{n} \beta_i,
\end{split}
\end{equation}
 Prove the following in-equation is correct or not,
\begin{equation}
\label{xxxxxxx}
\begin{split}	
\sum\limits_{i=1}^{m} (\alpha_i+\dfrac{1}{\alpha_i}) < \sum\limits_{i=1}^{n} (\beta_i+\dfrac{1}{\beta_i}),
\end{split}
\end{equation}
We propose a small contradiction to prove \ref{xxxxxxx} is not true.
When $m=2,n=1$, and $\alpha_1=1, \alpha_2=0.5, \beta=2.1$, we can see that although $\sum_{i=1}^m\alpha_i=1.5 < \sum_{i=1}^n\beta_i=2.1$, there is
$\sum_{i=1}^m(\alpha_i+\frac{1}{\alpha_i})=4.5 > \sum_{i=1}^n(\beta_i+\frac{1}{\beta_i})=2.58$.
hence, with WBS's update, it is possible that $U'> U$, thus there is no monotonically convergence by utilizing \ref{selfishutility}.

\end{proof}

Notice that the last four items in \ref{xxxxx} is exactly the change of summation of utilities of all WBSs after $i$' update if WhiteCat is executed, hence the monotonic convergence of WhiteCat is proved here analytically if noise is considered to be zero. If noise is considered, we can follow the conclusion in the end of \ref{gameforproblem} that WhiteCat converges without monotonicity.





%\appendix
%\addcontentsline{toc}{section}{Appendix~\ref{QLP}: reformulation of \ref{QLP}}
\chapter{Deviation of Problem \ref{QLP}}
\label{optdeviation}
We reformulate the objective problem \ref{QLP} which is a binary non-linear programming to binary quadratic programming as follows,

	\begin{equation}	
\label{QLP2_1}
		\begin{aligned}
%		\begin{split}
		& \sum\limits^{n}_{i=1} \frac{\sum\limits_{j\in\mathcal{N}, j\neq i}\vec{P}^T_jX_j(X_j^TX_i)h_{ji}z_{ji} + N_0}{\vec{P}^T_iX_ih_iz_i}\\
		& =\sum\limits^{n}_{i=1}( \frac{\sum\limits_{j\in\mathcal{N}, j\neq i}\sum\limits_k (P_{jk}\cdot x_{jk}\cdot x_{ik}\cdot x_{jk}\cdot h_{ji}\cdot z_{ji}) + \sum\limits_k N_0\cdot x_{i k}}{\vec{P}_i^TX_ih_iz_i})\\
		& =\sum\limits^{n}_{i=1}( \frac{\sum\limits_{j\in\mathcal{N}, j\neq i}\sum\limits_k (P_{jk}\cdot x_{jk}\cdot x_{ik}\cdot h_{ji}\cdot z_{ji})}{\vec{P}^T_iX_ih_iz_i}  + \frac{\sum\limits_k N_0\cdot x_{ik}}{\vec{P}^T_iX_ih_iz_i})\\
		& =\sum\limits^{n}_{i=1}( \sum\limits_{j\in\mathcal{N}, j\neq i}\sum\limits_k \frac{(P_{jk}\cdot x_{jk}\cdot x_{ik}\cdot h_{ji}\cdot z_{ji})}{\vec{P}^T_iX_ih_iz_i}  + \sum\limits_k\frac{N_0\cdot x_{ik}}{\vec{P}^T_iX_ih_iz_i})
%		\end{split}
		\end{aligned}
	\end{equation}

If we assume WBS $i$ is working on channel $m$, then there is $x_{im}=1$, then the first item in the parenthesis becomes,
	\begin{equation}
		\label{QLP2_22}
				\begin{aligned}
				 &\frac{P_{jk}\cdot x_{jk}\cdot x_{ik}\cdot h_{ji}\cdot z_{ji}}{\vec{P}^T_iX_ih_iz_i}
				 &= \frac{P_{jk}\cdot x_{jk}\cdot x_{im}\cdot h_{ji}\cdot z_{ji}}{P_{im}\cdot x_{im} \cdot h_i\cdot z_i} \\
				 &= \frac{P_{jk}\cdot x_{jk}\cdot x_{im}\cdot h_{ji}\cdot z_{ji}}{P_{im}\cdot h_i\cdot z_i}
		 	\end{aligned}
	\end{equation}
%other wise, formula \ref{QLP2_22} equals to 0.

Similarly, for the second item in the parenthesis,		

	\begin{equation}
\label{QLP2_4}
			\frac{N_0\cdot x_{ik}}{P^TX_ih_iz_i} = \frac{N_0}{P_{ik}h_iz_i}\cdot x_{ik}
	\end{equation}		
		
then, formula \ref{QLP2_1} becomes,
	\begin{equation}
\label{QLP2_5}
			\sum\limits^{n}_{i=1}( \sum\limits_{j\in\mathcal{N}, j\neq i}\sum\limits_k \frac{P_{jk}\cdot h_{ji}\cdot z_{ji}}{P_{ik}\cdot h_i\cdot z_i}\cdot  x_{jk}\cdot x_{ik}  + \sum\limits_k \frac{N_0}{P_{ik}\cdot h_i\cdot z_i}\cdot x_{ik})
		\end{equation}	

which is a binary quadratic programming problem.
\end{appendices}
